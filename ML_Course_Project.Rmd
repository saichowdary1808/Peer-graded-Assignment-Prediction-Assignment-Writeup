predictDT <- predict(modFitDT, subTesting, type = "class")



# Plot result

rpart.plot(modFitDT, main="Classification Tree", extra=102, under=TRUE, faclen=0)

```



Following confusion matrix shows the errors of the prediction algorithm.



```{r decisiontreecm, echo=TRUE}

confusionMatrix(predictDT, subTesting$classe)

```



### Random forest

```{r randomforest, echo=TRUE}

# Fit model

modFitRF <- randomForest(classe ~ ., data=subTraining, method="class")



# Perform prediction

predictRF <- predict(modFitRF, subTesting, type = "class")

```



Following confusion matrix shows the errors of the prediction algorithm.



```{r randomforestcm, echo=TRUE}

confusionMatrix(predictRF, subTesting$classe)

```



## Conclusion



### Result



The confusion matrices show, that the Random Forest algorithm performens better than decision trees. The accuracy for the Random Forest model was 0.995 (95% CI: (0.993, 0.997)) compared to 0.739 (95% CI: (0.727, 0.752)) for Decision Tree model. The random Forest model is choosen.



### Expected out-of-sample error

The expected out-of-sample error is estimated at 0.005, or 0.5%. The expected out-of-sample error is calculated as 1 - accuracy for predictions made against the cross-validation set. Our Test data set comprises 20 cases. With an accuracy above 99% on our cross-validation data, we can expect that very few, or none, of the test samples will be missclassified.



## Submission

In this section the files for the project submission are generated using the random forest algorithm on the testing data.



```{r submission, echo=TRUE}

# Perform prediction

predictSubmission <- predict(modFitRF, testing, type="class")

predictSubmission



# Write files for submission

pml_write_files = function(x){

  n = length(x)

  for(i in 1:n){

    filename = paste0("./data/submission/problem_id_",i,".txt")

    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)

  }

}



pml_write_files(predictSubmission)
